{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 : Variational AutoEncoders (VAE) for MNIST Images -- exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS5242_2025_codes/labs_lecture08/lab02_vae_image'\n",
    "    print(path_to_file)\n",
    "    # move to Google Drive directory\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL) # remove warnings\n",
    "\n",
    "# PyTorch version and GPU\n",
    "print(torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device= torch.device(\"cuda\") # use GPU\n",
    "else:\n",
    "    device= torch.device(\"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "print(train_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE with Transformers\n",
    "\n",
    "The VAE encoder is designed as follows:\n",
    "* It begins with a convolutional layer that reduces the input image size from 1 x n x n (grayscale) to d x n/2 x n/2, where d is the hidden dimension. \n",
    "* A second convolutional layer further downsamples the feature map from d x n/2 x n/2 to d x n/4 x n/4.\n",
    "* This is followed by a linear layer that flattens the output to a vector of size d.\n",
    "* Two additional linear layers are used to produce dz-dimensional vectors for the mean and variance of the Gaussian distribution. \n",
    "* 2D batch normalization layer and layer normalization are applied before ReLU activation function. \n",
    "* The final output of the encoder is a latent vector z, which is sampled from the learned Gaussian distribution.\n",
    "\n",
    "The VAE decoder reconstructs the image from the latent representation using a symmetric process:\n",
    "* It starts with two linear layers that map the latent vector z to a feature map of size d x n/4 x n/4. \n",
    "* The decoder then applies two transposed convolutional layers to upsample the feature map from d x n/4 x n/4 to d x n/2 x n/2 and finally to the original image size of 1 x n x n. \n",
    "* The reconstructed image, x_hat, is obtained by applying a sigmoid activation function, ensuring the pixel values are constrained to the range [0,1].\n",
    "\n",
    "Hints: You may use PyTorch modules `nn.Conv2d`, `nn.ConvTranspose2d`, `nn.BatchNorm2d`, `nn.LayerNorm`, `torch.randn`, and `torch.sigmoid`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "n = train_data.size(1) # n : nb of pixels along each spatial dimension\n",
    "dz = 36 # dz : latent dimension\n",
    "d = 256 # d : hidden dimension\n",
    "b = 250 # b : batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define  VAE architecture\n",
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder x => z\n",
    "        self.conv1_enc = # COMPLETE HERE  #  1 x 28 x 28 --> d x 14 x 14\n",
    "        self.bn1_enc = # COMPLETE HERE \n",
    "        self.conv2_enc = # COMPLETE HERE  #  d x 14 x 14 --> d x 7 x 7\n",
    "        self.bn2_enc = # COMPLETE HERE \n",
    "        self.linear_q = # COMPLETE HERE \n",
    "        self.ln = # COMPLETE HERE \n",
    "        self.linear_q_mu     = # COMPLETE HERE \n",
    "        self.linear_q_logvar = # COMPLETE HERE \n",
    "\n",
    "        # Decoder z => x\n",
    "        self.linear1_dec = # COMPLETE HERE \n",
    "        self.ln_dec = # COMPLETE HERE \n",
    "        self.linear2_dec = # COMPLETE HERE \n",
    "        self.conv1_dec = # COMPLETE HERE  #  d x 7 x 7 --> d x 14 x 14\n",
    "        self.bn1_dec = # COMPLETE HERE \n",
    "        self.conv2_dec = # COMPLETE HERE  #  d x 14 x 14 --> 1 x 28 x 28\n",
    "        \n",
    "    def forward(self, x, train=True): \n",
    "        \n",
    "        if train:\n",
    "            # Encoder x => z\n",
    "            h = # COMPLETE HERE \n",
    "            q_mu = # COMPLETE HERE \n",
    "            q_logvar = # COMPLETE HERE \n",
    "            q_std = # COMPLETE HERE \n",
    "            eps = # COMPLETE HERE \n",
    "            z = # COMPLETE HERE \n",
    "        else:\n",
    "            # Sample unit Normal distribution\n",
    "            z = torch.Tensor(x.size(0), dz).normal_(mean=0.0, std=1.0).to(device) # [b, dz]\n",
    "            q_mu, q_logvar = _, _\n",
    "            \n",
    "        # Decoder z => x\n",
    "        h = # COMPLETE HERE \n",
    "        x_hat = # COMPLETE HERE \n",
    "        \n",
    "        return x_hat, q_mu, q_logvar\n",
    "    \n",
    "    \n",
    "# Instantiate the network\n",
    "net = VAE()\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "utils.display_num_param(net) \n",
    "\n",
    "# Test the forward pass, backward pass and gradient update with a single batch\n",
    "init_lr = 0.001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=init_lr)\n",
    "idx = torch.LongTensor(b).random_(0,60000)\n",
    "batch_images = train_data[idx,:,:].to(device) # [b, n, n]\n",
    "print(batch_images.size())\n",
    "optimizer.zero_grad()\n",
    "x_hat, q_mu, q_logvar = net(batch_images) # [b, n, n], [b, dz], [b, dz]\n",
    "print(x_hat.size())\n",
    "# loss\n",
    "p_x = batch_images # we assume that images are Bernoulli distribution\n",
    "p_xz = x_hat       # we do not perform Bernoulli sampling\n",
    "loss_data =  nn.BCELoss()(p_xz, p_x)\n",
    "loss_KL = -0.5* torch.mean( 1.0 + q_logvar - q_mu.pow(2.0) - q_logvar.exp() )\n",
    "loss = 10* loss_data + loss_KL\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "net = VAE()\n",
    "net = net.to(device)\n",
    "utils.display_num_param(net) \n",
    "\n",
    "# Optimizer\n",
    "init_lr = 0.0003\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=init_lr)\n",
    "\n",
    "nb_batch = 100 \n",
    "b = 200  # Batch size\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(nb_batch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    shuffled_indices = torch.randperm(60000)\n",
    "    \n",
    "    for count in range(0,60000,b):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "        idx = shuffled_indices[count : count+b]\n",
    "        batch_images = train_data[idx,:,:].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, q_mu, q_logvar = net(batch_images) \n",
    "        # loss\n",
    "        p_x = batch_images # we assume that images are Bernoulli distribution\n",
    "        p_xz = x_hat       # we do not perform Bernoulli sampling\n",
    "        loss_data =  nn.BCELoss()(p_xz, p_x)\n",
    "        loss_KL = -0.5* torch.mean( 1.0 + q_logvar - q_mu.pow(2.0) - q_logvar.exp() )\n",
    "        loss = loss_data + 1/4*loss_KL \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # COMPUTE STATS\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches += 1        \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', init_lr  ,'\\t loss=', total_loss )\n",
    "    \n",
    "    # PLOT\n",
    "    if epoch>0 and not epoch%20:\n",
    "        with torch.no_grad():\n",
    "            num_generated_images = 16\n",
    "            x = torch.zeros(num_generated_images, n**2).to(device)\n",
    "            x_hat = net(x, False)[0]\n",
    "            x_hat = x_hat.squeeze().detach().to('cpu')\n",
    "        figure, axis = plt.subplots(4, 4)\n",
    "        figure.set_size_inches(10,10)\n",
    "        i,j,cpt=0,0,0; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=1,0,1; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=2,0,2; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=3,0,3; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=0,1+0,4; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=1,1+0,5; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=2,1+0,6; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=3,1+0,7; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=0,2+0,8; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=1,2+0,9; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=2,2+0,10; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=3,2+0,11; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=0,3+0,12; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=1,3+0,13; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=2,3+0,14; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        i,j,cpt=3,3+0,15; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated images with VAE\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    num_generated_images = 16\n",
    "    x = torch.zeros(num_generated_images, n**2).to(device)\n",
    "    x_hat = net(x, False)[0]\n",
    "    print('x_hat',x_hat.size())\n",
    "    x_hat = x_hat.squeeze().detach().to('cpu')\n",
    "\n",
    "figure, axis = plt.subplots(4, 4)\n",
    "figure.set_size_inches(10,10)\n",
    "\n",
    "i,j,cpt=0,0,0; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=1,0,1; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=2,0,2; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=3,0,3; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=0,1+0,4; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=1,1+0,5; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=2,1+0,6; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=3,1+0,7; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=0,2+0,8; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=1,2+0,9; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=2,2+0,10; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=3,2+0,11; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=0,3+0,12; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=1,3+0,13; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=2,3+0,14; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "i,j,cpt=3,3+0,15; axis[i,j].imshow(x_hat[cpt,:,:], cmap='gray'); axis[i,j].set_title(\"Generated w/ VAE\"); axis[i,j].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
